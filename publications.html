<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Thang D. Bui</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="members.html">Members</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="vacancies.html">Vacancies</a></div>
</td>
<td id="layout-content">
<h2>Preprints</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2202.12275" target=&ldquo;blank&rdquo;>Partitioned Variational Inference: A Framework for Probabilistic Federated Learning</a><br />Matthew Ashman, Thang Bui, Cuong Nguyen, Stratis Markou, Adrian Weller, Siddharth Swaroop, Richard Turner<br />Note: An old version of this is available <a href="https://arxiv.org/abs/1811.11206" target=&ldquo;blank&rdquo;>here</a>.
</p>
</li>
</ul>
<h2>Conference and journal papers</h2>
<ul>
<li><p>q-Paths: Generalizing the geometric annealing path using power means<br /> Vaden Masrani, Rob Brekelmans, Thang Bui, Frank Nielsen , Aram Galstyan, Greg Ver Steeg, and Frank Wood <br /> UAI 2021
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2006.05468" target=&ldquo;blank&rdquo;>Variational autoregressive Gaussian processes for continual learning</a><br /> Sanyam Kapoor, Theofanis Karaletsos, and Thang Bui <br /> ICML 2021 <br /> <a href="https://github.com/uber-research/vargp" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2002.04033" target=&ldquo;blank&rdquo;>Hierarchical Gaussian process priors for Bayesian neural network weights</a><br /> Theofanis Karaletsos and Thang Bui <br /> NeurIPS 2020
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1710.10628" target=&ldquo;blank&rdquo;>Variational continual learning</a><br /> Cuong Nguyen, Yingzhen Li, Thang Bui, and Rich Turner, <br /> ICLR 2018 <br /> <a href="https://github.com/nvcuong/variational-continual-learning" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1703.04818" target=&ldquo;blank&rdquo;>Neural graph learning: Training neural networks using graphs</a><br /> Thang Bui, Sujith Ravi, and Vivek Ramavajjala <br /> WSDM 2018
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1605.07066" target=&ldquo;blank&rdquo;>A unifying framework for sparse Gaussian process approximations using Power Expectation Propagation</a><br /> Thang Bui, Josiah Yan, Rich Turner <br /> JMLR 2017 <br /> <a href="https://github.com/thangbui/sparseGP_powerEP/" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1705.07131" target=&ldquo;blank&rdquo;>Streaming sparse Gaussian process approximations</a><br /> Thang Bui, Cuong Nguyen, and Rich Turner <br /> NIPS 2017 <br /> <a href="https://github.com/thangbui/streaming_sparse_gp" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="http://jmlr.org/proceedings/papers/v48/bui16.pdf" target=&ldquo;blank&rdquo;>Deep Gaussian processes for regression using approximate Expectation Propagation</a><br /> Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato, and Rich Turner <br /> ICML 2016 <br /> <a href="https://github.com/thangbui/deepGP_approxEP/" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="http://jmlr.org/proceedings/papers/v48/hernandez-lobatob16.pdf" target=&ldquo;blank&rdquo;>Black-box alpha-divergence minimization</a><br /> José Miguel Hernández-Lobato, Yingzhen Li, Mark Rowland, Daniel Hernández-Lobato, Thang Bui, and Rich Turner <br /> ICML 2016 <br /> <a href="https://bitbucket.org/jmh233/code_black_box_alpha_icml_2016" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
<li><p><a href="https://papers.nips.cc/paper/5772-learning-stationary-time-series-using-gaussian-processes-with-nonparametric-kernels" target=&ldquo;blank&rdquo;>Learning stationary time series using Gaussian processes with nonparametric kernels</a> <br /> Felipe Tobar, Thang Bui, and Rich Turner <br /> NIPS 2015 (<b>Spotlight</b>, acceptance rate = 3.6%)
</p>
</li>
<li><p><a href="https://papers.nips.cc/paper/5459-tree-structured-gaussian-process-approximations" target=&ldquo;blank&rdquo;>Tree-structured Gaussian process approximations</a><br /> Thang Bui and Rich Turner <br /> NIPS 2014 (<b>Spotlight</b>, acceptance rate = 3.6%) <br /> <a href="https://github.com/thangbui/tsgp/" target=&ldquo;blank&rdquo;>code</a>
</p>
</li>
</ul>
<h2>Thesis</h2>
<ul>
<li><p><a href="docs/papers/thesis-thang.pdf" target=&ldquo;blank&rdquo;>Efficient Deterministic Approximate Bayesian Inference for Gaussian Process Models</a> <br /> PhD thesis <br /> University of Cambridge <br /> <a href="docs/papers/thesis-thang-typos.txt" target=&ldquo;blank&rdquo;>typos in the print version</a> 
</p>
</li>
</ul>
<h2>Workshop papers</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2012.07823" target=&ldquo;blank&rdquo;>Annealed importance sampling with q-paths</a><br /> Rob Brekelmans, Vaden Masrani, Thang Bui, Frank Wood, Aram Galstyan, Greg Ver Steeg, and Frank Nielsen, <br /> NeurIPS workshop on Deep Learning through Information Geometry, 2020<br /> <b>Best paper award</b>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2006.05468" target=&ldquo;blank&rdquo;>Variational autoregressive Gaussian processes for continual learning</a> <br /> Sanyam Kapoor, Theofanis Karaletsos, and Thang Bui <br /> ICML workshop on Continual Learning, 2020
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2002.04033" target=&ldquo;blank&rdquo;>Gaussian process meta-representations for hierarchical neural network priors</a><br /> Theofanis Karaletsos and Thang Bui <br /> 2nd Symposium on Advances in Approximate Bayesian Inference, 2019
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1811.11206" target=&ldquo;blank&rdquo;>Partitioned variational inference for federated Bayesian deep learning</a><br /> Thang Bui, Cuong Nguyen, Siddharth Swaroop, and Rich Turner <br /> NeurIPS Bayesian Deep Learning Workshop, 2018
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1905.02099" target=&ldquo;blank&rdquo;>Understanding and improving variational continual learning</a><br /> Siddharth Swaroop, Cuong Nguyen, Thang Bui, and Rich Turner <br /> NeurIPS Continual Learning Workshop, 2018
</p>
</li>
<li><p><a href="https://hanna-tseran.github.io/files/NeurIPS_Continual_Learning_Workshop_2018_Paper.pdf" target=&ldquo;blank&rdquo;>Natural variational continual learning</a><br /> Hanna Tseran, Emtiyaz Khan, Tatsuya Harada and Thang Bui <br /> NeurIPS Continual Learning Workshop, 2018
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1710.10628" target=&ldquo;blank&rdquo;>Variational continual learning for deep models</a><br /> Cuong Nguyen, Yingzhen Li, Thang Bui, and Rich Turner <br /> NIPS Bayesian Deep Learning Workshop, 2017
</p>
</li>
<li><p><a href="http://roseyu.com/time-series-workshop/submissions/TSW2017_paper_7.pdf" target=&ldquo;blank&rdquo;>Online variational Bayesian inference: Algorithms for sparse Gaussian processes and theoretical bounds</a><br /> Cuong Nguyen, Thang Bui, Yingzhen Li, and Rich Turner <br /> ICML Time Series Workshop, 2017
</p>
</li>
<li><p><a href="https://jmhldotorg.files.wordpress.com/2013/10/papernipsworkshopbayesiandeeplearning2016.pdf" target=&ldquo;blank&rdquo;>Importance weighted autoencoders with random neural network parameters</a><br /> Daniel Hernández-Lobato, Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, and Rich Turner <br /> NIPS Workshop on Bayesian Deep Learning, 2016
</p>
</li>
<li><p><a href="http://approximateinference.org/accepted/BuiEtAl2016.pdf" target=&ldquo;blank&rdquo;>Black-box alpha divergence for generative models</a><br /> Thang Bui, Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Yingzhen Li, and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2016
</p>
</li>
<li><p><a href="http://approximateinference.org/accepted/TebbuttEtAl2016.pdf" target=&ldquo;blank&rdquo;>Circular Pseudo-point approximations for scaling Gaussian processes</a><br /> Will Tebbutt, Thang Bui and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2016
</p>
</li>
<li><p>Bayesian Gaussian process state space models via Power-EP <br /> Thang Bui, Carl Rasmussen and Rich Turner <br />  ICML Workshop on Data efficient Machine Learning, 2016
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1511.03405" target=&ldquo;blank&rdquo;>Training deep Gaussian processes using stochastic expectation propagation and probabilistic backpropagation</a><br /> Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2015
</p>
</li>
<li><p><a href="https://www.blackboxworkshop.org/pdf/gplvm_blackbox_final.pdf" target=&ldquo;blank&rdquo;>Stochastic variational inference for Gaussian process latent variable models using back constraints</a><br /> Thang Bui and Rich Turner <br /> NIPS Workshop on Black Box Learning and Inference, 2015
</p>
</li>
<li><p><a href="https://www.blackboxworkshop.org/pdf/nips2015_blackbox_alpha.pdf" target=&ldquo;blank&rdquo;>Black-box alpha-divergence minimisation</a><br /> José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato, Thang Bui and Rich Turner <br /> NIPS Workshops on Advances in Approximate Bayesian Inference and Black Box Learning and Inference, 2015.
</p>
</li>
<li><p><a href="https://arxiv.org/abs/1511.03249" target=&ldquo;blank&rdquo;>Stochastic expectation propagation for large scale Gaussian process classification</a><br /> Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Yingzhen Li, Thang Bui and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2015.
</p>
</li>
<li><p><a href="http://learning.eng.cam.ac.uk/pub/Public/Turner/Publications/Tobar_Bui_Turner_NIPS15_TS.pdf" target=&ldquo;blank&rdquo;>Design of covariance functions using inter-domain inducing variables</a><br /> Felipe Tobar, Thang Bui and Rich Turner<br />  NIPS Workshop on Time Series, 2015<br /> <b>Best paper award</b>
</p>
</li>
</ul>
<h2>Misc</h2>
<ul>
<li><p><a href="docs/reports/tvo_annealed_is.pdf" target=&ldquo;blank&rdquo;>Connecting the Thermodynamic Variational Objective and Annealed Importance Sampling</a><br /> Thang Bui
</p>
</li>
<li><p><a href="docs/reports/tr_sparseNonConj.pdf" target=&ldquo;blank&rdquo;>Sparse Approximations for Non-Conjugate Gaussian Process Regressions</a><br /> Thang Bui and Rich Turner
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
