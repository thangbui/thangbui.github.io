<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="style/thang.css" type="text/css" />
<title>Thang Bui</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Thang Bui</h1>
</div>
<div class="infoblock">
<div class="blockcontent">
<p>I'm a lecturer (equivalent to tenure-track Assistant Professor) in Machine Learning and Data Science at the University of Sydney, Australia.<br />
I'm taking leave to spend time at Uber AI, working on probabilistic modelling, approximate inference, continual learning, model-based reinforcement learning, and bandits.<br /><br /> 
I completed my doctoral training at the <a href="http://mlg.eng.cam.ac.uk">Cambridge Machine Learning group</a>, supervised by <a href="http://cbl.eng.cam.ac.uk/Public/Turner/WebHome">Richard Turner</a> and advised by <a href="http://learning.eng.cam.ac.uk/carl/">Carl Rasmussen</a>. I worked on Gaussian process models and generic approximation methods.<br /><br /></p>
</div></div>
<h2>Preprints</h2>
<dl>
<dt>Variational autoregressive Gaussian processes for continual learning</dt>
<dd><p>Sanyam Kapoor, Theofanis Karaletsos, Thang Bui <br /> <a href="https://arxiv.org/abs/2006.05468">https://arxiv.org/abs/2006.05468</a></p></dd>
<dt>Hierarchical Gaussian process priors for Bayesian neural network weights</dt>
<dd><p>Theofanis Karaletsos, Thang Bui <br /> <a href="https://arxiv.org/abs/2002.04033">https://arxiv.org/abs/2002.04033</a></p></dd>
<dt>Partitioned Variational Inference: A unified framework encompassing federated and continual learning</dt>
<dd><p>Thang Bui, Cuong Nguyen, Siddharth Swaroop, Rich Turner<br /> <a href="https://arxiv.org/abs/1811.11206">https://arxiv.org/abs/1811.11206</a></p></dd>
</dl>
<h2>Conference and journal papers</h2>
<dl>
<dt>Variational Continual Learning</dt>
<dd><p>Cuong Nguyen, Yingzhen Li, Thang Bui, and Rich Turner, <br /> ICLR 2018 <br /> <a href="https://arxiv.org/abs/1710.10628">arxiv</a></p></dd>
<dt>Neural graph learning: Training neural networks using graphs</dt>
<dd><p>Thang Bui, Sujith Ravi, and Vivek Ramavajjala <br /> WSDM 2018 <br /> <a href="https://arxiv.org/abs/1703.04818">arxiv</a></p></dd>
<dt>A Unifying Framework for Sparse Gaussian Process Approximation using Power Expectation Propagation</dt>
<dd><p>Thang Bui, Josiah Yan, Rich Turner <br /> JMLR 2017 <br /> <a href="https://arxiv.org/abs/1605.07066">arxiv</a> <a href="https://github.com/thangbui/sparseGP_powerEP/">code</a></p></dd>
<dt>Streaming Sparse Gaussian Process Approximations</dt>
<dd><p>Thang Bui, Cuong Nguyen, and Rich Turner <br /> NIPS 2017 <br /> <a href="https://arxiv.org/abs/1705.07131">arxiv</a> <a href="https://github.com/thangbui/streaming_sparse_gp">code</a></p></dd>
<dt>Deep Gaussian Processes for Regression using Approximate Expectation Propagation</dt>
<dd><p>Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato, and Rich Turner <br /> ICML 2016 <br /> <a href="http://jmlr.org/proceedings/papers/v48/bui16.pdf">paper</a> <a href="https://github.com/thangbui/deepGP_approxEP/">code</a></p></dd>
<dt>Black-box alpha-divergence minimization</dt>
<dd><p>José Miguel Hernández-Lobato, Yingzhen Li, Mark Rowland, Daniel Hernández-Lobato, Thang Bui, and Rich Turner <br /> ICML 2016 <br /> <a href="http://jmlr.org/proceedings/papers/v48/hernandez-lobatob16.pdf">paper</a> <a href="https://bitbucket.org/jmh233/code_black_box_alpha_icml_2016">code</a></p></dd>
<dt>Learning stationary time series using Gaussian processes with nonparametric kernels</dt>
<dd><p>Felipe Tobar, Thang Bui, and Rich Turner <br /> NIPS 2015 (<b>Spotlight</b>, acceptance rate = 3.6%) <br /> <a href="https://papers.nips.cc/paper/5772-learning-stationary-time-series-using-gaussian-processes-with-nonparametric-kernels">paper</a></p></dd>
<dt>Tree-structured Gaussian process approximations</dt>
<dd><p>Thang Bui and Rich Turner <br /> NIPS 2014 (<b>Spotlight</b>, acceptance rate = 3.6%) <br /> <a href="https://papers.nips.cc/paper/5459-tree-structured-gaussian-process-approximations">paper</a> <a href="https://github.com/thangbui/tsgp/">code</a></p></dd>
</dl>
<h2>Thesis</h2>
<dl>
<dt>Efficient Deterministic Approximate Bayesian Inference for Gaussian Process Models</dt>
<dd><p>PhD thesis <br /> University of Cambridge <br /> <a href="docs/papers/thesis-thang.pdf">pdf</a> <br /> <a href="docs/papers/thesis-thang-typos.txt">typos in the print version</a> </p></dd>
</dl>
<h2>Workshop papers</h2>
<dl>
<dt>Partitioned variational inference for federated Bayesian deep learning</dt>
<dd><p>Thang Bui, Cuong Nguyen, Siddharth Swaroop, and Rich Turner <br /> NeurIPS Bayesian Deep Learning Workshop, 2018</p></dd>
<dt>Understanding and improving variational continual learning</dt>
<dd><p>Siddharth Swaroop, Cuong Nguyen, Thang Bui, and Rich Turner <br /> NeurIPS Continual Learning Workshop, 2018</p></dd>
<dt>Natural variational continual learning</dt>
<dd><p>Hanna Tseran, Emtiyaz Khan, Tatsuya Harada and Thang Bui <br /> NeurIPS Continual Learning Workshop, 2018</p></dd>
<dt>Variational continual learning for deep models</dt>
<dd><p>Cuong Nguyen, Yingzhen Li, Thang Bui, and Rich Turner <br /> NIPS Bayesian Deep Learning Workshop, 2017</p></dd>
<dt>Online variational Bayesian inference: Algorithms for sparse Gaussian processes and theoretical bounds</dt>
<dd><p>Cuong Nguyen, Thang Bui, Yingzhen Li, and Rich Turner <br /> ICML Time Series Workshop, 2017</p></dd>
<dt>Importance weighted autoencoders with random neural network parameters</dt>
<dd><p>Daniel Hernández-Lobato, Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, and Rich Turner <br /> NIPS Workshop on Bayesian Deep Learning, 2016</p></dd>
<dt>Black-box alpha divergence for generative models</dt>
<dd><p>Thang Bui, Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Yingzhen Li, and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2016</p></dd>
<dt>Circular Pseudo-point approximations for scaling Gaussian processes</dt>
<dd><p>Will Tebbutt, Thang Bui and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2016</p></dd>
<dt>Bayesian Gaussian process state space models via Power-EP</dt>
<dd><p>Thang Bui, Carl Rasmussen and Rich Turner <br />  ICML Workshop on Data efficient Machine Learning, 2016</p></dd>
<dt>Training deep Gaussian processes using stochastic expectation propagation and probabilistic backpropagation</dt>
<dd><p>Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2015</p></dd>
<dt>Stochastic variational inference for Gaussian process latent variable models using back constraints</dt>
<dd><p>Thang Bui and Rich Turner <br /> NIPS Workshop on Black Box Learning and Inference, 2015</p></dd>
<dt>Black-box alpha-divergence minimisation</dt>
<dd><p>José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato, Thang Bui and Rich Turner <br /> NIPS Workshops on Advances in Approximate Bayesian Inference and Black Box Learning and Inference, 2015.</p></dd>
<dt>Stochastic expectation propagation for large scale Gaussian process classification</dt>
<dd><p>Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Yingzhen Li, Thang Bui and Rich Turner <br /> NIPS Workshop on Advances in Approximate Bayesian Inference, 2015.</p></dd>
<dt>Design of covariance functions using inter-domain inducing variables</dt>
<dd><p>Felipe Tobar, Thang Bui and Rich Turner<br />  NIPS Workshop on Time Series, 2015 <b>Best paper prize</b></p></dd>
</dl>
<h2>Misc</h2>
<dl>
<dt>Sparse Approximations for Non-Conjugate Gaussian Process Regressions</dt>
<dd><p>Thang Bui and Rich Turner <br /> <a href="docs/reports/tr_sparseNonConj.pdf">report</a></p></dd>
</dl>
<h2>Other things</h2>
<p>Reviewer for JMLR (2016, 2017, 2018), NIPS (2016-20), ICLR (2017-20), ICML (2017-20), AISTATS (2018-20), UAI (2018) and various NIPS and ICML workshops</p>
<h2>Contact</h2>
<p>thang.buivn at at at at gmail.com</p>
<div id="footer">
<div id="footer-text">
Page generated 2020-06-16 12:00:18 +07, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
